{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484dfea-9ac4-4558-968f-09cf3e030633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from utils.driver_state import determine_drive_state_changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395d9e7-7815-4197-8c3e-932c0d93b1da",
   "metadata": {},
   "source": [
    "## Calculate driver change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca63ab2-5043-40f9-9523-8622985c1f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load optical flow data\n",
    "optical_flow_data = torch.load(\n",
    "    \"resources/optical-flow/optical_flow.pkl\", weights_only=False\n",
    ")\n",
    "records = []\n",
    "\n",
    "# Iterate over the optical flow data to prepare a list of records\n",
    "for video_filename, frames in optical_flow_data.items():\n",
    "    # Correct video name format if needed\n",
    "    if video_filename == \"video_00013.mp4\":\n",
    "        video_filename = \"video_0013.mp4\"\n",
    "\n",
    "    for frame_info in frames:\n",
    "        records.append(\n",
    "            {\n",
    "                \"filename\": video_filename,\n",
    "                \"frame\": frame_info[\"frame\"],\n",
    "                \"score\": frame_info[\"score\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "optical_flow_df = pd.DataFrame(records)\n",
    "\n",
    "# Extract the video name from the filename\n",
    "optical_flow_df[\"video\"] = optical_flow_df[\"filename\"].apply(\n",
    "    lambda filename: filename.split(\".\")[0]\n",
    ")\n",
    "\n",
    "# Add driver state change information\n",
    "video_groups = []\n",
    "for video_id, video_group in optical_flow_df.groupby(\"video\"):\n",
    "    # Backfill the missing score values\n",
    "    time_series_scores = video_group[\"score\"].bfill().reset_index(drop=True)\n",
    "\n",
    "    # Determine the driver state change based on the backfilled scores\n",
    "    video_group[\"change_bkp4\"] = determine_drive_state_changed(\n",
    "        time_series_scores, n_bkps=4\n",
    "    )\n",
    "\n",
    "    video_groups.append(video_group)\n",
    "\n",
    "# Concatenate all video groups into a single DataFrame\n",
    "final_optical_flow_df = pd.concat(video_groups).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d0136-f305-49bd-bdf9-6c42c4fa0c73",
   "metadata": {},
   "source": [
    "## Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa266c-9cd1-468a-bad5-f4c40ccdef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submission structure\n",
    "submission_df = pd.read_csv(\"./submissions/results_driverstate_alltracks_bboxsizes.csv\")\n",
    "submission_df[\"frame\"] = submission_df[\"ID\"].apply(\n",
    "    lambda id_str: int(id_str.split(\"_\")[-1])\n",
    ")\n",
    "submission_df[\"video\"] = submission_df[\"ID\"].apply(\n",
    "    lambda id_str: \"_\".join(id_str.split(\"_\")[:2])\n",
    ")\n",
    "\n",
    "# Load annotations\n",
    "with open(\"./resources/annotations_public.pkl\", \"rb\") as annotation_file:\n",
    "    annotations = pickle.load(annotation_file)\n",
    "\n",
    "# Prepare data structure for merging\n",
    "annotation_data = []\n",
    "for video_id, video_annotations in annotations.items():\n",
    "    for frame_id, frame_annotations in video_annotations.items():\n",
    "        annotation_data.append(\n",
    "            {\n",
    "                \"ID\": f\"{video_id}_{frame_id}\",\n",
    "                \"video\": video_id,\n",
    "                \"frame\": frame_id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Create DataFrame from annotations\n",
    "annotation_df = pd.DataFrame(annotation_data)\n",
    "\n",
    "# Merge annotations with submission data\n",
    "merged_df = pd.merge(\n",
    "    left=annotation_df, right=submission_df, how=\"left\", on=[\"video\", \"frame\"]\n",
    ")\n",
    "\n",
    "# Forward-fill missing data for each video\n",
    "filled_df = merged_df.groupby(\"video\").apply(lambda group: group.ffill())\n",
    "filled_df = filled_df.reset_index(drop=True)\n",
    "\n",
    "# Prepare final submission data\n",
    "final_submission_df = filled_df[[\"ID\", \"change_bkp4\"]].reset_index(drop=True)\n",
    "final_submission_df = final_submission_df.rename(\n",
    "    {\"change_bkp4\": \"Driver_State_Changed\"}, axis=1\n",
    ")\n",
    "\n",
    "# Save final submission to CSV\n",
    "final_submission_df.to_csv(\n",
    "    \"./submissions/results_driverstate_alltracks_opticalflow.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
