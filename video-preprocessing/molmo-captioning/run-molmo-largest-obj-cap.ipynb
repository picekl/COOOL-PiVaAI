{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4041ee-e80e-45fd-8dad-26f8859f91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import get_area, get_img, crop_square_with_context, get_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f4279-dcd8-4772-aead-8f8d9e81ae2e",
   "metadata": {},
   "source": [
    "## Load MOLMO and Ground Truth annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d68991f-86be-4496-a160-0342cd6aded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"allenai/Molmo-7B-D-0924\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"allenai/Molmo-7B-D-0924\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "\n",
    "# Load annotations\n",
    "with open(\"../../resources/annotations_public.pkl\", \"rb\") as f:\n",
    "    anns = pickle.load(f)\n",
    "\n",
    "# Process annotation to get area\n",
    "data = []\n",
    "for video, video_data in anns.items():\n",
    "    for frame, frame_data in video_data.items():\n",
    "        for track in frame_data[\"challenge_object\"]:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"video\": video,\n",
    "                    \"frame\": frame,\n",
    "                    \"track_id\": track[\"track_id\"],\n",
    "                    \"bbox\": track[\"bbox\"],\n",
    "                    \"area\": get_area(track[\"bbox\"]),\n",
    "                }\n",
    "            )\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073d8c7-6334-4989-bab0-9536bad86dd1",
   "metadata": {},
   "source": [
    "\n",
    "## Run MOLMO\n",
    "- For each object in each video:\n",
    "    - Do inference for top 5 largest boxes in video\n",
    "    - Crop square to prevent distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df679a-ea9f-4c44-a934-e1a3bbbf3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Propose 5 most likely class labels of the object, context of the image is traffic and unusual hazards such as various animals on the road. Write only the class names separated by spaces.\n",
    "    \"\"\"\n",
    "\n",
    "data = defaultdict(list)\n",
    "for (video, track_id), group in tqdm(df.groupby([\"video\", \"track_id\"])):\n",
    "    select = group.sort_values(by=\"area\", ascending=False).head(5)\n",
    "    for _, row in select.iterrows():\n",
    "        img = get_img(f\"{video}.mp4\", frame_id=row[\"frame\"])\n",
    "        img_crop = crop_square_with_context(img, row[\"bbox\"], 0.0)\n",
    "        text = get_text(img_crop, prompt, processor, model)\n",
    "        text = text.strip(\" \").replace(\"\\n\", \" \")\n",
    "        data[video, track_id].append(text)\n",
    "\n",
    "data = dict(data)\n",
    "torch.save(data, f\"results/molmo-obj-cap-largest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb31d9f-e975-4860-ac59-da922a8f961b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
