{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T14:17:23.406967Z",
     "start_time": "2024-12-18T14:17:22.034014Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "from ioutils import load_pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Guide\n",
    "- Install Depth-Anything accordingly to [the instructions](https://huggingface.co/depth-anything/Depth-Anything-V2-Large)."
   ],
   "id": "eac710a81e1fe5df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:17:26.246054Z",
     "start_time": "2024-12-18T14:17:23.411703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Large\n",
    "model = DepthAnythingV2(encoder='vitl', features=256, out_channels=[256, 512, 1024, 1024])\n",
    "model.load_state_dict(torch.load('checkpoints/depth_anything_v2_vitl.pth', map_location='cpu'))\n",
    "\n",
    "# Base\n",
    "# model = DepthAnythingV2(encoder='vitb', features=128, out_channels=[96, 192, 384, 768])\n",
    "# model.load_state_dict(torch.load('checkpoints/depth_anything_v2_vitb.pth', map_location='cpu'))\n",
    "\n",
    "# Small\n",
    "# model = DepthAnythingV2(encoder='vits', features=64, out_channels=[48, 96, 192, 384])\n",
    "# model.load_state_dict(torch.load('checkpoints/depth_anything_v2_vits.pth', map_location='cpu'))\n",
    "\n",
    "model.eval().to(device)\n",
    "\n",
    "# raw_img = cv2.imread('/home/marek/Work/COOOL_benchmark/coool/experiment/assets/examples/demo01.jpg')\n",
    "# raw_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2RGB)\n",
    "# raw_img = torch.from_numpy(raw_img).unsqueeze(0).to(device)\n",
    "# depth = model.infer_image(raw_img) # HxW raw depth map\n",
    "# Image.fromarray(depth).show()"
   ],
   "id": "54a598f462765e1c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90289/2270525560.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('checkpoints/depth_anything_v2_vitl.pth', map_location='cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DepthAnythingV2(\n",
       "  (pretrained): DinoVisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-23): 24 x NestedTensorBlock(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MemEffAttention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (depth_head): DPTHead(\n",
       "    (projects): ModuleList(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2-3): 2 x Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (resize_layers): ModuleList(\n",
       "      (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (2): Identity()\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (scratch): Module(\n",
       "      (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (refinenet1): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet2): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet3): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet4): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (output_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (output_conv2): Sequential(\n",
       "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:17:26.674365Z",
     "start_time": "2024-12-18T14:17:26.285624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "annotations_path = \"../data/annotations_public.pkl\"\n",
    "annotations = load_pickle(annotations_path)\n",
    "video_root = \"/home/marek/datasets/coool-benchmark\"\n"
   ],
   "id": "c7dfdc4ca728b142",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:23:44.097689Z",
     "start_time": "2024-12-18T14:17:26.679081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "video_names = sorted(list(annotations.keys()))\n",
    "for video_name in tqdm(video_names, total=len(video_names)):\n",
    "\n",
    "    video_path = osp.join(video_root, f\"{video_name}.mp4\")\n",
    "\n",
    "    video_name = Path(video_path).stem\n",
    "    video_data = []\n",
    "    video_stream = cv2.VideoCapture(video_path)\n",
    "    fps = video_stream.get(cv2.CAP_PROP_FPS)\n",
    "    if not video_stream.isOpened():\n",
    "        raise ValueError(f\"Video {video_name} could not be opened.\")\n",
    "\n",
    "    frame = 0\n",
    "    while video_stream.isOpened():\n",
    "        ret, frame_image = video_stream.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame % fps == 0:\n",
    "            depth = model.infer_image(frame_image)\n",
    "            # depth_normalized = depth / depth.max() * 255\n",
    "            # depth_captures[video_name][frame] = depth_normalized.astype(np.uint8)\n",
    "            img_path = osp.join(\"../results/depth_captures\", f\"{video_name}_{frame}.jpeg\")\n",
    "            cv2.imwrite(img_path, depth)\n",
    "\n",
    "        frame += 1\n",
    "    video_stream.release()\n"
   ],
   "id": "fbab95703685b793",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [06:17<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
